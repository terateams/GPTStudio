import json

import streamlit as st
import sys
import os
from dotenv import load_dotenv
from llama_index.llms import ChatMessage
from libs.llama_utils import get_llama_memary_index, get_llama_store_index, create_document_index_by_texts
from libs.session import PageSessionState
from llama_index.tools import QueryEngineTool, ToolMetadata, RetrieverTool
from llama_index.agent import OpenAIAgent
from libs.prompts import get_content_from

sys.path.append(os.path.abspath('..'))
load_dotenv()


def get_ragsbot_page(botname):
    page_state = PageSessionState(botname)
    # st.sidebar.markdown("# ğŸ’¡Python ç¼–ç¨‹å¯¼å¸ˆ")

    # ç”¨äºå­˜å‚¨å¯¹è¯è®°å½•, ç¬¬ä¸€æ¡ä¸ºæ¬¢è¿æ¶ˆæ¯
    page_state.initn_attr("messages", [])
    # ç”¨äºæ ‡è®°ä¸Šä¸€æ¡ç”¨æˆ·æ¶ˆæ¯æ˜¯å¦å·²ç»å¤„ç†
    page_state.initn_attr("last_user_msg_processed", True)
    # ç”¨äºæ ‡è®°æµå¼è¾“å‡ºæ˜¯å¦ç»“æŸ
    page_state.initn_attr("streaming_end", True)

    def end_chat_streaming():
        """å½“åœæ­¢æŒ‰é’®è¢«ç‚¹å‡»æ—¶æ‰§è¡Œï¼Œç”¨äºä¿®æ”¹å¤„ç†æ ‡å¿—"""
        page_state.streaming_end = True
        page_state.last_user_msg_processed = True

    def start_chat_streaming():
        """å½“å¼€å§‹æŒ‰é’®è¢«ç‚¹å‡»æ—¶æ‰§è¡Œï¼Œç”¨äºä¿®æ”¹å¤„ç†æ ‡å¿—"""
        page_state.streaming_end = False
        page_state.last_user_msg_processed = False

    def on_input_prompt(iprompt: str):
        if iprompt.strip() == "":
            return
        page_state.chat_prompt = iprompt
        start_chat_streaming()
        page_state.add_chat_msg("messages", {"role": "user", "content": page_state.chat_prompt})
        with st.chat_message("user"):
            st.write(page_state.chat_prompt)

    # æ–‡æœ¬ç±»æ–‡ä»¶ä¸Šä¼ 
    files = st.sidebar.file_uploader("ä¸Šä¼ æ–‡ä»¶",
                                     type=["txt", "docx", "doc", "pdf", "pptx", "ppt", "xls", "xlsx",
                                           "epub", "mobi", "md", "py", "js", "html", "css",
                                           "json", "yaml", "java", "yml", "ini", "toml",
                                           "csv", "tsv", "xml", "log", "rst", "sh",
                                           "bat", "ps1", "psm1", "psd1", "ps1xml",
                                           "pssc", "psrc", ],
                                     accept_multiple_files=True)

    if st.sidebar.button("ç´¢å¼•æ–‡ä»¶"):
        if files:
            texts = [f.getvalue() for f in files]
            create_document_index_by_texts(texts, "ragsbot.chroma.db", "default_collection")

    for msg in page_state.messages:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    if not page_state.rags_load:
        st.warning("è¯·ä¸Šä¼ æ–‡ä»¶")
        st.stop()

    rindex = get_llama_store_index("ragsbot.chroma.db", "default_collection")
    agent = OpenAIAgent.from_tools(
        [
            # QueryEngineTool(
            #     query_engine=rindex.as_query_engine(similarity_top_k=10),
            #     metadata=ToolMetadata(
            #         name=f"radius_index1_{botname}",
            #         description="Query all questions related to the radius protocol",
            #     )),
            RetrieverTool(
                retriever=rindex.as_retriever(similarity_top_k=3),
                metadata=ToolMetadata(
                    name=f"radius_index2_{botname}",
                    description="Query all questions related to the radius protocol, in detail.",
                )
            )
        ],
        system_prompt=get_content_from("ragsbot"),
        verbose=True
    )

    # ç”¨æˆ·è¾“å…¥
    if not page_state.last_user_msg_processed:
        st.chat_input("è¯·ç­‰å¾…ä¸Šä¸€æ¡æ¶ˆæ¯å¤„ç†å®Œæ¯•", disabled=True)
    else:
        if prompt := st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜"):
            on_input_prompt(prompt)

    stop_action = st.sidebar.empty()
    if not page_state.streaming_end:
        stop_action.button('åœæ­¢è¾“å‡º', on_click=end_chat_streaming, help="ç‚¹å‡»æ­¤æŒ‰é’®åœæ­¢æµå¼è¾“å‡º")

    # ç”¨æˆ·è¾“å…¥å“åº”ï¼Œå¦‚æœä¸Šä¸€æ¡æ¶ˆæ¯ä¸æ˜¯åŠ©æ‰‹çš„æ¶ˆæ¯ï¼Œä¸”ä¸Šä¸€æ¡ç”¨æˆ·æ¶ˆæ¯è¿˜æ²¡æœ‰å¤„ç†å®Œæ¯•
    if (page_state.messages
            and page_state.messages[-1]["role"] != "assistant"
            and not page_state.last_user_msg_processed):
        with st.chat_message("assistant"):
            with st.spinner("Thinking..."):
                messages = [ChatMessage(role=m["role"], content=m["content"]) for m in page_state.messages[-10:-1]]
                response = agent.stream_chat(page_state.chat_prompt, chat_history=messages)
                # æµå¼è¾“å‡º
                placeholder = st.empty()
                full_response = ''
                page_state.add_chat_msg("messages", {"role": "assistant", "content": ""})
                for token in response.response_gen:
                    # # å¦‚æœç”¨æˆ·æ‰‹åŠ¨åœæ­¢äº†æµå¼è¾“å‡ºï¼Œå°±é€€å‡ºå¾ªç¯
                    if page_state.streaming_end:
                        break
                    if token is not None:
                        full_response += token
                        placeholder.markdown(full_response)
                        page_state.update_last_msg("messages", {"role": "assistant", "content": full_response})
                placeholder.markdown(full_response)

        stop_action.empty()
        end_chat_streaming()

    st.sidebar.download_button('å¯¼å‡ºå¯¹è¯å†å²',
                               data=json.dumps(page_state.messages, ensure_ascii=False),
                               file_name="chat_history.json", mime="application/json")

    if st.sidebar.button('æ¸…é™¤å¯¹è¯å†å²'):
        page_state.messages = []
        st.rerun()
