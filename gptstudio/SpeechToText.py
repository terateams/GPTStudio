from dotenv import load_dotenv
load_dotenv()
import uuid

import streamlit as st
from st_audiorec import st_audiorec
from openai import OpenAI
from pydub import AudioSegment
from datetime import timedelta
from common.utils import get_global_datadir
from common.speech import audio_segment_split, generate_openai_transcribe
from common.openai import openai_text_generate
from hashlib import md5
import io
import sys
import os
import srt
from common.session import PageSessionState

st.sidebar.title("ğŸ”Š è¯­éŸ³åˆ›ä½œ âœ¨")

page_state = PageSessionState("speech")
# ç”¨äºå­˜å‚¨ä¸´æ—¶æ–‡ä»¶
audio_tempdir = get_global_datadir("temp_audio")
page_state.initn_attr("input_type", "microphone")
page_state.initn_attr("audio_text_source", None)
page_state.initn_attr("recode_text", None)
page_state.initn_attr("latest_custom_file", None)

st.markdown(
    """
    <style>
    /* Target code blocks */
    .stCodeBlock > div {
        white-space: pre-wrap !important;
    }
    </style>
    """,
    unsafe_allow_html=True,
)


@st.cache_data(persist="disk")
def get_speech(filename, language: str = "en"):
    return generate_openai_transcribe(filename, language, format="text")


def get_speech_text(audio_path, language):
    basename = os.path.basename(audio_path)
    audio_format = basename.split(".")[-1]
    audio_segment = AudioSegment.from_file(audio_path, format=audio_format)
    segs = audio_segment_split(audio_segment, 120)
    page_state.recode_text = ""
    for seg in segs:
        md5hash = md5(seg.raw_data).hexdigest()
        seg_audio_path = os.path.join(audio_tempdir, md5hash + ".mp3")
        seg.export(seg_audio_path, format="mp3")
        text = get_speech(seg_audio_path, language)
        page_state.recode_text += "\n" + text
    return page_state.recode_text

with st.sidebar:
    language = st.selectbox("é€‰æ‹©æºè¯­è¨€", ["zh", "en"], index=0)

wav_audio_recode = None
audio_path = None


tab1, tab2 = st.tabs(["å½•åˆ¶è¯­éŸ³", "ä¸Šä¼ éŸ³é¢‘"])

with tab1:
    wav_audio_recode = st_audiorec()
    if st.button("è¯†åˆ«è¯­éŸ³", key="do_recode"):
        if wav_audio_recode is not None:
            status = st.status("æ­£åœ¨è¯†åˆ«å½•åˆ¶è¯­éŸ³....", state="running", expanded=True)
            with status:
                status.update(label="æ­£åœ¨ä¿å­˜è¯­éŸ³....")
                _filename = md5(wav_audio_recode[:100]).hexdigest()
                # _filename = uuid.uuid4().hex
                audio_segment = AudioSegment.from_wav(io.BytesIO(wav_audio_recode))
                audio_path = os.path.join(audio_tempdir, f"{_filename}.audio.wav")
                audio_segment.export(audio_path, format="wav")
                status.update(label="å·²ä¿å­˜è¯­éŸ³ï¼Œ æ­£åœ¨è¯†åˆ«....")
                result = get_speech_text(audio_path, language)
                status.update(label="è¯†åˆ«å®Œæˆ", state="complete")
        else:
            st.warning("æ²¡æœ‰å½•åˆ¶åˆ°è¯­éŸ³")

with tab2:
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶", type=["wav", "mp3", "mp4", "ogg", "m4a"]
    )
    if uploaded_file:
        audio_path = os.path.join(audio_tempdir, os.path.basename(uploaded_file.name))
        with open(audio_path, "wb") as f:
            f.write(uploaded_file.getvalue())
        st.audio(audio_path)

    if audio_path and st.button("è¯†åˆ«è¯­éŸ³", key="do_uploadfile"):
        with st.spinner("æ­£åœ¨è¯†åˆ«ä¸Šä¼ è¯­éŸ³...."):
            result = get_speech_text(audio_path, language)


st.divider()

if page_state.recode_text:
    st.code(page_state.recode_text)


if st.sidebar.button("æ¸…é™¤å†å²æ•°æ®", type="secondary"):
    page_state.recode_text = None
    st.rerun()
    