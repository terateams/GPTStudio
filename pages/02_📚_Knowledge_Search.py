import streamlit as st
import os
import sys
from dotenv import load_dotenv
from libs.knowledge import search_knowledge, knowledge_dictionary
from libs.msal import msal_auth
from llama_index import VectorStoreIndex, SimpleDirectoryReader

sys.path.append(os.path.abspath('..'))
load_dotenv()


# Authenticate the user via the msal_auth() function
with st.sidebar:
    value = msal_auth()
    if value is None:
        st.stop()

st.markdown("## ğŸ“š çŸ¥è¯†åº“æœç´¢")
st.markdown("çŸ¥è¯†åº“æ£€ç´¢ï¼Œè¾“å…¥ä¸»é¢˜ï¼Œæ£€ç´¢ç›¸å…³çŸ¥è¯†ã€‚")


if "knowledge_messages" not in st.session_state.keys():
    st.session_state.knowledge_messages = [{"role": "assistant", "content": "æ¬¢è¿ä½¿ç”¨çŸ¥è¯†åº“æ£€ç´¢ï¼Œ è¯·è¾“å…¥ä¸»é¢˜"}]

collection = st.sidebar.selectbox("é€‰æ‹©çŸ¥è¯†åº“", knowledge_dictionary.keys())
collection_value = knowledge_dictionary[collection]

for knowledge_messages in st.session_state.knowledge_messages:
    with st.chat_message(knowledge_messages["role"]):
        st.write(knowledge_messages["content"])


def clear_chat_history():
    st.session_state.knowledge_messages = [{"role": "assistant", "content": "æ¬¢è¿ä½¿ç”¨çŸ¥è¯†åº“æ£€ç´¢ï¼Œè¯·è¾“å…¥ä¸»é¢˜"}]


st.sidebar.button('æ¸…é™¤å†å²', on_click=clear_chat_history)


if prompt := st.chat_input("è¾“å…¥æ£€ç´¢ä¸»é¢˜"):
    st.session_state.knowledge_messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

if st.session_state.knowledge_messages[-1]["role"] != "assistant":
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            response = search_knowledge(collection_value, prompt)
            if response is None:
                response = "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çŸ¥è¯†"
            st.markdown(response)
    message = {"role": "assistant", "content": response}
    st.session_state.knowledge_messages.append(message)
